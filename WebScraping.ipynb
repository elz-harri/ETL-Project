{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open browser\n",
    "browser = Browser('chrome')\n",
    "url = 'http://quotes.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get author born, \n",
    "def quote_author(url):\n",
    "    author_info = {}\n",
    "    \n",
    "    # request author html data\n",
    "    authorPage = requests.get(url).text\n",
    "    \n",
    "    # parse response\n",
    "    author = BeautifulSoup(authorPage, 'html.parser')\n",
    "    \n",
    "    # find author details\n",
    "    author_info['name'] = author.find('h3', class_ = 'author-title').text\n",
    "    author_info['birthday'] = author.find('span', class_ = 'author-born-date').text\n",
    "    author_info['location'] = author.find('span', class_ = 'author-born-location').text\n",
    "    author_info['description'] = author.find('div', class_ = 'author-description').text.strip()\n",
    "    \n",
    "    return author_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tags\n",
    "def get_tags(quote):\n",
    "    tagList = []\n",
    "    \n",
    "    quoteTags = quote.find_all('a', class_='tag')\n",
    "    \n",
    "    for tag in quoteTags:\n",
    "        tagList.append(tag.text)\n",
    "    \n",
    "    return tagList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get quote info\n",
    "def quote_data(quote):\n",
    "    quote_info = {}\n",
    "    quote_info['quote_text'] = quote.find('span', class_='text').text\n",
    "    auth_url = urljoin(url, quote.find('a')['href'])\n",
    "    \n",
    "    # get author data\n",
    "    quote_info['author'] = quote_author(auth_url)\n",
    "    \n",
    "    # get tag data\n",
    "    quote_info['tag'] = get_tags(quote)\n",
    "    \n",
    "    return quote_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of quote boxes\n",
    "def get_quoteList(pageNumber):\n",
    "    quoteList = []\n",
    "    \n",
    "    # get html data from current page\n",
    "    html = browser.html\n",
    "    \n",
    "    # use BeautifulSoup to parse html data\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # find all quote blocks\n",
    "    quotes = soup.find_all('div', class_='quote')\n",
    "    \n",
    "    # initialize quote ids\n",
    "    quoteID = (pageNumber - 1) * 10\n",
    "    \n",
    "    # for each quote in the list retuned\n",
    "    for quote in quotes:\n",
    "        # increment quote id\n",
    "        quoteID += 1\n",
    "        \n",
    "        # get all quote data returned as a dictionary\n",
    "        quote_dic = quote_data(quote)\n",
    "        quote_dic['_id'] = quoteID\n",
    "        \n",
    "        quoteList.append(quote_dic)\n",
    "    \n",
    "#         quoteList[0]: {_id: 1,\n",
    "#                         quote_text: ,\n",
    "#                         author:{name:\n",
    "#                                 birthday:      \n",
    "#                                 born:\n",
    "#                                 description:}\n",
    "#                         tags: []\n",
    "#                       }\n",
    "    \n",
    "    return quoteList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape everything\n",
    "def scrap_everything(url):\n",
    "    all_quotes = []\n",
    "    \n",
    "    first_iterations = True\n",
    "    nextPage = True\n",
    "    pageNumber = 1\n",
    "    \n",
    "    while nextPage == True:\n",
    "        \n",
    "        # if this is the first time through the while loop, navigate to url \n",
    "        if first_iterations == True:\n",
    "            browser.visit(url)\n",
    "            first_iterations = False\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # get all quote data from the page\n",
    "        print(f'Scraping Page {pageNumber}')\n",
    "        currentList = get_quoteList(pageNumber)\n",
    "        all_quotes =  all_quotes + currentList\n",
    "        \n",
    "        try:\n",
    "            browser.links.find_by_partial_text('Next').click()\n",
    "            pageNumber += 1  \n",
    "        except:\n",
    "            print(\"Scraping Complete\")\n",
    "            nextPage = False\n",
    "    \n",
    "    return all_quotes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Page 1\n",
      "Scraping Page 2\n",
      "Scraping Page 3\n",
      "Scraping Page 4\n",
      "Scraping Page 5\n",
      "Scraping Page 6\n",
      "Scraping Page 7\n",
      "Scraping Page 8\n",
      "Scraping Page 9\n",
      "Scraping Page 10\n",
      "Scraping Complete\n"
     ]
    }
   ],
   "source": [
    "data = scrap_everything(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection\n",
    "db = client.quoteslist_db\n",
    "collection = db.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7fc859a13580>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary to be inserted as a MongoDB document\n",
    "collection.insert_many(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
