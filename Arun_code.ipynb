{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup \n",
    "from urllib.parse import urljoin\n",
    "import pymongo\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening chromedriver browser\n",
    "browser = Browser('chrome')\n",
    "url = 'insert url here'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the details about the author from author page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this functions takes the url from the author page, scrpae the information from the page and return\n",
    "#a dictionary\n",
    "\n",
    "def get_author(url):\n",
    "    results = {}\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    result['born'] = soup.find('span', class_='author-born-date').text.strip()\n",
    "    result['name'] = soup.h3.text.strip()\n",
    "    result['description'] = soup.find('div', class_='author-description').text.strip()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags_for_quote(quote_soup):\n",
    "    tags=[]\n",
    "    for rag in quote_soup.find_all('a',class_='tag'):\n",
    "        tags.append(tag.text)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get all the details about one quote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quote(quote_soup):\n",
    "    quote = ()\n",
    "    quote['text'] = quote_soup.span.text\n",
    "    quote['author'] = quote_soup.find('small',class_='author').text\n",
    "    href=quote_soup.a['href']\n",
    "    author_url = urljoin(url,href)\n",
    "    #for this quote get the author details now\n",
    "    quote['author']=get_author(author_url)\n",
    "    quote['tags']=get_tags_for_quote(quote_soup)\n",
    "    return quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quotes_on_a_page(page_number):\n",
    "    result=[]\n",
    "    html=browser.html\n",
    "    soup=BeautifulSoup(html,'lxml')\n",
    "    quote=soup.find_all('div',class_='quote')\n",
    "    number_of_quotes_per_page=10\n",
    "    quote_id=(page_number-1)*number_of_quotes_per_page\n",
    "    for quote in quotes:\n",
    "        quote_id = quote_id + 1\n",
    "        quote_info =get_quote(quote)\n",
    "        quote_info['_id'] = quote_id\n",
    "        result.append(quote_info)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_quotes(url):\n",
    "    more_quotes =True\n",
    "    first_iterations = True\n",
    "    page_number = 0\n",
    "    quotes = []\n",
    "    while more_quotes:\n",
    "        page_number += 1\n",
    "        print(f'Now scrapping page : {page_number}')\n",
    "        if first_iterations:\n",
    "            browser.visit(url)\n",
    "            first_iterations =False\n",
    "        else:\n",
    "            pass:\n",
    "        quote_on_this_page = get_quotes_on_a_page(page_number)\n",
    "        quotes = quotes + quotes_on_this_page\n",
    "        try:\n",
    "            next = browser.links.find_by_partial_text('Next')\n",
    "            print('about to click on the next link')\n",
    "            if(next.is_empty()):\n",
    "                more_quotes=False\n",
    "            else:\n",
    "                next.click()\n",
    "        except Exception as ex:\n",
    "            print('Scraping Complete')\n",
    "            print(ex.message)\n",
    "            more_quotes = False\n",
    "    return quotes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
